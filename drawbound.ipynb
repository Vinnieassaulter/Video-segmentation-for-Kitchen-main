{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiyang/anaconda3/envs/kosmos-2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[78, 77, 67],\n",
       "        [77, 76, 66],\n",
       "        [76, 75, 65],\n",
       "        ...,\n",
       "        [24, 29, 27],\n",
       "        [29, 34, 32],\n",
       "        [34, 39, 37]],\n",
       "\n",
       "       [[78, 77, 67],\n",
       "        [77, 76, 66],\n",
       "        [76, 75, 65],\n",
       "        ...,\n",
       "        [24, 29, 27],\n",
       "        [32, 37, 35],\n",
       "        [39, 44, 42]],\n",
       "\n",
       "       [[78, 77, 67],\n",
       "        [77, 76, 66],\n",
       "        [76, 75, 65],\n",
       "        ...,\n",
       "        [25, 30, 28],\n",
       "        [36, 41, 39],\n",
       "        [44, 49, 47]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[71, 73, 67],\n",
       "        [60, 62, 56],\n",
       "        [47, 49, 43],\n",
       "        ...,\n",
       "        [68, 75, 68],\n",
       "        [68, 75, 68],\n",
       "        [68, 75, 68]],\n",
       "\n",
       "       [[71, 73, 67],\n",
       "        [61, 63, 57],\n",
       "        [48, 50, 44],\n",
       "        ...,\n",
       "        [68, 75, 68],\n",
       "        [68, 75, 68],\n",
       "        [68, 75, 68]],\n",
       "\n",
       "       [[71, 73, 67],\n",
       "        [61, 63, 57],\n",
       "        [49, 51, 45],\n",
       "        ...,\n",
       "        [68, 75, 68],\n",
       "        [68, 75, 68],\n",
       "        [68, 75, 68]]], dtype=uint8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def is_overlapping(rect1, rect2):\n",
    "    x1, y1, x2, y2 = rect1\n",
    "    x3, y3, x4, y4 = rect2\n",
    "    return not (x2 < x3 or x1 > x4 or y2 < y3 or y1 > y4)\n",
    "\n",
    "\n",
    "def draw_entity_boxes_on_image(image, entities, show=False, save_path=None):\n",
    "    \"\"\"_summary_\n",
    "    Args:\n",
    "        image (_type_): image or image path\n",
    "        collect_entity_location (_type_): _description_\n",
    "    \"\"\"\n",
    "    if isinstance(image, Image.Image):\n",
    "        image_h = image.height\n",
    "        image_w = image.width\n",
    "        image = np.array(image)[:, :, [2, 1, 0]]\n",
    "    elif isinstance(image, str):\n",
    "        if os.path.exists(image):\n",
    "            pil_img = Image.open(image).convert(\"RGB\")\n",
    "            image = np.array(pil_img)[:, :, [2, 1, 0]]\n",
    "            image_h = pil_img.height\n",
    "            image_w = pil_img.width\n",
    "        else:\n",
    "            raise ValueError(f\"invaild image path, {image}\")\n",
    "    elif isinstance(image, torch.Tensor):\n",
    "        # pdb.set_trace()\n",
    "        image_tensor = image.cpu()\n",
    "        reverse_norm_mean = torch.tensor([0.48145466, 0.4578275, 0.40821073])[:, None, None]\n",
    "        reverse_norm_std = torch.tensor([0.26862954, 0.26130258, 0.27577711])[:, None, None]\n",
    "        image_tensor = image_tensor * reverse_norm_std + reverse_norm_mean\n",
    "        pil_img = T.ToPILImage()(image_tensor)\n",
    "        image_h = pil_img.height\n",
    "        image_w = pil_img.width\n",
    "        image = np.array(pil_img)[:, :, [2, 1, 0]]\n",
    "    else:\n",
    "        raise ValueError(f\"invaild image format, {type(image)} for {image}\")\n",
    "\n",
    "    if len(entities) == 0:\n",
    "        return image\n",
    "\n",
    "    new_image = image.copy()\n",
    "    previous_bboxes = []\n",
    "    # size of text\n",
    "    text_size = 1\n",
    "    # thickness of text\n",
    "    text_line = 1  # int(max(1 * min(image_h, image_w) / 512, 1))\n",
    "    box_line = 3\n",
    "    (c_width, text_height), _ = cv2.getTextSize(\"F\", cv2.FONT_HERSHEY_COMPLEX, text_size, text_line)\n",
    "    base_height = int(text_height * 0.675)\n",
    "    text_offset_original = text_height - base_height\n",
    "    text_spaces = 3\n",
    "\n",
    "    for entity_name, (start, end), bboxes in entities:\n",
    "        for (x1_norm, y1_norm, x2_norm, y2_norm) in bboxes:\n",
    "            orig_x1, orig_y1, orig_x2, orig_y2 = int(x1_norm * image_w), int(y1_norm * image_h), int(x2_norm * image_w), int(y2_norm * image_h)\n",
    "            # draw bbox\n",
    "            # random color\n",
    "            color = tuple(np.random.randint(0, 255, size=3).tolist())\n",
    "            new_image = cv2.rectangle(new_image, (orig_x1, orig_y1), (orig_x2, orig_y2), color, box_line)\n",
    "\n",
    "            l_o, r_o = box_line // 2 + box_line % 2, box_line // 2 + box_line % 2 + 1\n",
    "\n",
    "            x1 = orig_x1 - l_o\n",
    "            y1 = orig_y1 - l_o\n",
    "\n",
    "            if y1 < text_height + text_offset_original + 2 * text_spaces:\n",
    "                y1 = orig_y1 + r_o + text_height + text_offset_original + 2 * text_spaces\n",
    "                x1 = orig_x1 + r_o\n",
    "\n",
    "            # add text background\n",
    "            (text_width, text_height), _ = cv2.getTextSize(f\"  {entity_name}\", cv2.FONT_HERSHEY_COMPLEX, text_size, text_line)\n",
    "            text_bg_x1, text_bg_y1, text_bg_x2, text_bg_y2 = x1, y1 - (text_height + text_offset_original + 2 * text_spaces), x1 + text_width, y1\n",
    "\n",
    "            for prev_bbox in previous_bboxes:\n",
    "                while is_overlapping((text_bg_x1, text_bg_y1, text_bg_x2, text_bg_y2), prev_bbox):\n",
    "                    text_bg_y1 += (text_height + text_offset_original + 2 * text_spaces)\n",
    "                    text_bg_y2 += (text_height + text_offset_original + 2 * text_spaces)\n",
    "                    y1 += (text_height + text_offset_original + 2 * text_spaces)\n",
    "\n",
    "                    if text_bg_y2 >= image_h:\n",
    "                        text_bg_y1 = max(0, image_h - (text_height + text_offset_original + 2 * text_spaces))\n",
    "                        text_bg_y2 = image_h\n",
    "                        y1 = image_h\n",
    "                        break\n",
    "\n",
    "            alpha = 0.5\n",
    "            for i in range(text_bg_y1, text_bg_y2):\n",
    "                for j in range(text_bg_x1, text_bg_x2):\n",
    "                    if i < image_h and j < image_w:\n",
    "                        if j < text_bg_x1 + 1.35 * c_width:\n",
    "                            # original color\n",
    "                            bg_color = color\n",
    "                        else:\n",
    "                            # white\n",
    "                            bg_color = [255, 255, 255]\n",
    "                        new_image[i, j] = (alpha * new_image[i, j] + (1 - alpha) * np.array(bg_color)).astype(np.uint8)\n",
    "\n",
    "            cv2.putText(\n",
    "                new_image, f\"  {entity_name}\", (x1, y1 - text_offset_original - 1 * text_spaces), cv2.FONT_HERSHEY_COMPLEX, text_size, (0, 0, 0), text_line, cv2.LINE_AA\n",
    "            )\n",
    "            # previous_locations.append((x1, y1))\n",
    "            previous_bboxes.append((text_bg_x1, text_bg_y1, text_bg_x2, text_bg_y2))\n",
    "\n",
    "    pil_image = Image.fromarray(new_image[:, :, [2, 1, 0]])\n",
    "    if save_path:\n",
    "        pil_image.save(save_path)\n",
    "    if show:\n",
    "        pil_image.show()\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "# (The same image from the previous code example)\n",
    "# url = \"https://huggingface.co/ydshieh/kosmos-2-patch14-224/resolve/main/snowman.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "path = \"/media/data/qiyang/data/OH0037_2023_05_10_15_17_17/frames/Aoutput0_cut/frame_0.jpg\"\n",
    "image = Image.open(path)\n",
    "\n",
    "# From the previous code example\n",
    "entities = [('a snowman', (12, 21), [(0.390625, 0.046875, 0.984375, 0.828125)]), ('a fire', (41, 47), [(0.171875, 0.015625, 0.484375, 0.890625)])]\n",
    "\n",
    "# Draw the bounding bboxes\n",
    "draw_entity_boxes_on_image(image, entities, show=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kosmos-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
